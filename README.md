<p align="center" style="background-color:#EBFFFF">
  <a href="https://xugaoyi.com/" target="_blank" rel="noopener noreferrer">
    <img width="180" src="https://cdn.jsdelivr.net/gh/Cynicism-lab/MyResource@gh-pages/img/hmprint.png" alt="logo">
  </a>
</p>

<h1 align="center">HMPrint</h1>
<p align="center">An efficient and advanced model for identity authentication using physiological features</p>

# Introduction
The system, called **_HMPrint_**, uses outer ear microphones to capture air friction-induced acoustic effects (AFiSe) generated by head movements for identity verification.

# Demo
This is a demo video about HMPrint, mentioned in the paper **_Decoding Air Friction Rhythms: Enabling User Identification with Out-Ear
Microphones in COTS Earphones_**

https://user-images.githubusercontent.com/3998421/196976498-ba1ad3ab-fa18-4c55-965f-5c6683141375.mp4
