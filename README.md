<p align="center" style="background-color:#EBFFFF">
  <a href="https://xugaoyi.com/" target="_blank" rel="noopener noreferrer">
    <img width="180" src="https://cdn.jsdelivr.net/gh/Cynicism-lab/MyResource@gh-pages/img/hmprint.png" alt="logo">
  </a>
</p>

<h1 align="center">HMPrint</h1>
<p align="center">An efficient and advanced model for identity authentication using physiological features</p>

# Introduction
The system, called **_HMPrint_**, uses outer ear microphones to capture air friction-induced acoustic effects (AFiSe) generated by head movements for identity verification.

# Demo
This is a demo video including four head gestures about HMPrint, mentioned in the paper **_Decoding Air Friction Rhythms: Enabling User Identification with Out-Ear
Microphones in COTS Earphones_**

https://github.com/user-attachments/assets/074cf6e6-9a24-4fff-8e99-ceab7bec4664











